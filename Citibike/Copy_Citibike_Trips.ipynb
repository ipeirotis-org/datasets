{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMHhSrUQXoa0wB/0825a2p/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis-org/datasets/blob/main/Citibike/Copy_Citibike_Trips.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "5Gf6MX5bWLZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_PrGUgFU3h8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from google.cloud import storage\n",
        "\n",
        "# Replace these variables with your details\n",
        "gcs_bucket_name = 'citibike-archive'\n",
        "gcs_folder = 'tripdata'\n",
        "\n",
        "# Initialize the Google Cloud Storage client\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(gcs_bucket_name)\n",
        "\n",
        "# Function to download a file from a URL\n",
        "def download_file(url, local_filename):\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(local_filename, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    return local_filename\n",
        "\n",
        "# Function to upload a file to Google Cloud Storage\n",
        "def upload_to_gcs(local_file, bucket_name, destination_blob_name):\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "    blob.upload_from_filename(local_file)\n",
        "    print(f\"File {local_file} uploaded to {destination_blob_name}.\")\n",
        "\n",
        "# Main function to handle the download and upload\n",
        "def main():\n",
        "    base_url = 'https://s3.amazonaws.com/tripdata/'\n",
        "    years = range(2015, 2024 + 1)  # Adjust the range as needed\n",
        "    months = range(1, 12 + 1)\n",
        "\n",
        "    for year in years:\n",
        "        for month in months:\n",
        "            if year == 2015 and month <= 8:\n",
        "                continue\n",
        "            if year == 2024 and month >= 4:\n",
        "                continue\n",
        "            if year == 2022 and month == 7:\n",
        "                file_name = f\"JC-202207-citbike-tripdata.csv.zip\"\n",
        "            elif year == 2017 and month == 8:\n",
        "              file_name = f\"JC-201708%20citibike-tripdata.csv.zip\"\n",
        "            else:\n",
        "              file_name = f\"JC-{year:04d}{month:02d}-citibike-tripdata.csv.zip\"\n",
        "            url = base_url + file_name\n",
        "            local_file = file_name\n",
        "\n",
        "            try:\n",
        "                print(f\"Downloading {url}...\")\n",
        "                download_file(url, local_file)\n",
        "\n",
        "                gcs_destination = f\"{gcs_folder}/{file_name}\"\n",
        "                print(f\"Uploading {local_file} to gs://{gcs_bucket_name}/{gcs_destination}...\")\n",
        "                upload_to_gcs(local_file, gcs_bucket_name, gcs_destination)\n",
        "\n",
        "                # Remove local file after upload\n",
        "                os.remove(local_file)\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"Failed to download {url}: {e}\")\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "def load_csv_from_gcs(project_id, dataset_id, table_id, gcs_path):\n",
        "    client = bigquery.Client(project=project_id)\n",
        "\n",
        "    dataset_ref = client.dataset(dataset_id)\n",
        "    table_ref = dataset_ref.table(table_id)\n",
        "\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        source_format=bigquery.SourceFormat.CSV,\n",
        "        skip_leading_rows=1,  # Adjust if your CSV has a header row\n",
        "        autodetect=True,\n",
        "    )\n",
        "\n",
        "    load_job = client.load_table_from_uri(\n",
        "        gcs_path, table_ref, job_config=job_config\n",
        "    )\n",
        "\n",
        "    print(f\"Starting job {load_job.job_id}\")\n",
        "\n",
        "    load_job.result()  # Waits for the job to complete.\n",
        "\n",
        "    print(f\"Job finished. Loaded {load_job.output_rows} rows into {dataset_id}:{table_id}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    project_id = 'nyu-datasets'\n",
        "    dataset_id = 'citibike'\n",
        "    table_id = 'trips'\n",
        "    gcs_path = 'gs://citibike-archive/tripdata/*.csv.zip'\n",
        "\n",
        "    load_csv_from_gcs(project_id, dataset_id, table_id, gcs_path)\n"
      ],
      "metadata": {
        "id": "ITmyDbOpXaIJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}