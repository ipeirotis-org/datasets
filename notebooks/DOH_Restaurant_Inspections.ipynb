{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "https://www1.nyc.gov/site/doh/business/food-operators/the-inspection-process.page\n",
    "\n",
    "See https://www1.nyc.gov/assets/doh/downloads/pdf/rii/blue-book.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Download Latest Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "!curl 'https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD' -o restaurants.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "!rm restaurants.csv.gz\n",
    "!gzip restaurants.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"restaurants.csv.gz\", dtype = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "initial_size = len(df)\n",
    "initial_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Render our plots inline\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Adding underscores in all column names\n",
    "cols = df.columns\n",
    "cols = cols.map(lambda x: x.replace(' ', '_'))\n",
    "df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Cleaning Individual Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### INSPECTION_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df.INSPECTION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df.INSPECTION_TYPE.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# We create a column \"TO_DELETE\" to mark the entries that we are not interested in.\n",
    "# We will perform first the inspection/analysis on all the attributes, and then delete the rows\n",
    "\n",
    "# Drop all cases where inspection is NULL\n",
    "df['TO_DELETE'] = df.INSPECTION_TYPE.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Break INSPECTION_TYPE into two columns, and also delete some inspection types\n",
    "\n",
    "# Create a new column that contains the results of the split on the '/'' character\n",
    "lst = df.INSPECTION_TYPE.str.split(' / ').values.tolist()\n",
    "lst = [ l if type(l)==type(list()) else ['',''] for l in lst ]\n",
    "t = pd.DataFrame(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "t[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "t[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Keep only cycle inspections. Ignore admin, pre-permit, transfat, and calorie posting inspections\n",
    "# We will only keep the initial inspections and the re-inspections. The other types are border cases\n",
    "\n",
    "keep = df.INSPECTION_TYPE.isin( ['Cycle Inspection / Initial Inspection', 'Cycle Inspection / Re-inspection'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Check how many we will drop: ~keep means negation on the keep and summing up adds up the 'True'\n",
    "sum(~keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Adding the \"not keep\" entries into the TO_DELETE\n",
    "\n",
    "# The |= operator is a shortcut for df['TO_DELETE'] = df['TO_DELETE'] | ~keep\n",
    "# We use the bit-OR operator (|), as we want to keep the existing deletions, and add the ones from the \n",
    "# additional condition\n",
    "df['TO_DELETE'] |= ~keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Rename the two entries that we will keep into simpler values\n",
    "\n",
    "df[\"INSPECTION_TYPE\"].replace(\n",
    "    to_replace='Cycle Inspection / Initial Inspection',\n",
    "    value = 'Initial Inspection',\n",
    "    inplace=True\n",
    ")\n",
    "df[\"INSPECTION_TYPE\"].replace(\n",
    "    to_replace='Cycle Inspection / Re-inspection',\n",
    "    value = 'Re-inspection',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### BORO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df.BORO.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df.BORO.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Replace the \"Missing\" in BORO with null\n",
    "# df.BORO = df.BORO.replace('Missing', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "missing = set(df[df.BORO.isnull()].CAMIS)\n",
    "# missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df.BORO == 'Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Remove the entries with null/missing BORO value\n",
    "# Not worth trying to fix.\n",
    "df['TO_DELETE'] |= (df.BORO == 'Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df.BUILDING.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Inspect the entries with missing street number\n",
    "# df[df.BUILDING.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Dropping the violations listed without street number\n",
    "# Most are in train stations and in airports, but there\n",
    "# are a few others in 'regular' locations\n",
    "\n",
    "df['TO_DELETE'] |= df.BUILDING.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### STREET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Check that no street values are empty\n",
    "sum(df.STREET.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df['TO_DELETE'] |= df.STREET.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### ZIPCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df.ZIPCODE.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "len(set(df[df.ZIPCODE.isnull()].CAMIS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Filling zipcodes for Restaurants after normalization has occured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### CUISINE DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df.CUISINE_DESCRIPTION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "len(df.CUISINE_DESCRIPTION.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df.CUISINE_DESCRIPTION.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df.CUISINE_DESCRIPTION.replace(\n",
    "    to_replace='CafÃ©/Coffee/Tea',\n",
    "    value = 'Cafe',\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "df.CUISINE_DESCRIPTION.replace(\n",
    "    to_replace='Latin (Cuban, Dominican, Puerto Rican, South & Central American)',\n",
    "    value = 'Latin',\n",
    "    inplace=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### INSPECTION_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df[\"INSPECTION_DATE\"] = pd.to_datetime(df[\"INSPECTION_DATE\"], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "df.INSPECTION_DATE.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df.INSPECTION_DATE.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df.INSPECTION_DATE.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Drop the 1900-01-01 inspections. These are all incorrect and we cannot fix them\n",
    "df['TO_DELETE'] |= (df['INSPECTION_DATE'] == '1900-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# After analysis, it seems that we have minimal number of inspections before 2015\n",
    "df['TO_DELETE'] |=  (df['INSPECTION_DATE'] < '2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### ACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df.ACTION.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df[\"ACTION\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df[\"ACTION\"].replace(\n",
    "    to_replace='Violations were cited in the following area(s).',\n",
    "    value = 'Violations found',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df[\"ACTION\"].replace(\n",
    "    to_replace='No violations were recorded at the time of this inspection.',\n",
    "    value = 'No violations',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df[\"ACTION\"].replace(\n",
    "    to_replace='Establishment Closed by DOHMH.  Violations were cited in the following area(s) and those requiring immediate action were addressed.',\n",
    "    value = 'Establishment closed',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df[\"ACTION\"].replace(\n",
    "    to_replace='Establishment re-opened by DOHMH',\n",
    "    value = 'Establishment re-opened',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df[\"ACTION\"].replace(\n",
    "    to_replace='Establishment re-closed by DOHMH',\n",
    "    value = 'Establishment re-closed',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df[\"ACTION\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Drop the Establishment re-opened and re-closed cases\n",
    "# as the inspection scores for these can be misleading\n",
    "df['TO_DELETE'] |=  (df.ACTION == 'Establishment re-closed')\n",
    "df['TO_DELETE'] |=  (df.ACTION == 'Establishment re-opened')\n",
    "df['TO_DELETE'] |=  df.ACTION.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df[\"SCORE\"] = pd.to_numeric(df[\"SCORE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df.SCORE.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "len( df[ df.SCORE < 0 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df['TO_DELETE'] |= (df.SCORE < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Drop cases reported as \"no violations but with positive score\"\n",
    "df['TO_DELETE'] |= ((df.SCORE > 0)  & (df.ACTION == 'No violations'))\n",
    "\n",
    "# Drop cases with zero score but with violations found\n",
    "df['TO_DELETE'] |= ((df.SCORE == 0)  & (df.ACTION == 'Violations found'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Drop incorrectly scored inspections\n",
    "df['TO_DELETE'] |=  (df.GRADE=='A') & (df.SCORE>13)\n",
    "\n",
    "df['TO_DELETE'] |=  (df.GRADE=='B') & ( (df.SCORE<14) | (df.SCORE>27) )\n",
    "\n",
    "# Drop incorrectly scored inspections\n",
    "df['TO_DELETE'] |=  (df.GRADE=='C') & (df.SCORE<28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### RECORD_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df[\"RECORD_DATE\"] = pd.to_datetime(df[\"RECORD_DATE\"], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Drop record date field, as it only contains a single value\n",
    "df = df.drop( 'RECORD_DATE', axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### GRADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df.GRADE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "sum(df.GRADE.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df.query(\" GRADE == 'G' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Seems that all the \"G\" correspond to \"A\"\n",
    "df.GRADE.replace('G', 'A', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# P assigned to 'Establishment re-opened' actions\n",
    "df.query(\" GRADE == 'P' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# P assigned to 'Establishment re-opened' actions\n",
    "df.query(\" GRADE == 'P' \").ACTION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# P assigned to 'Reopening Inspection' inspection types\n",
    "df.query(\" GRADE == 'P' \").INSPECTION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# df.query(\" GRADE == 'Z' \").SCORE.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# TODO: Figure out what Z, and Not Yet Graded means in GRADE\n",
    "# Until then, we just replace these values with NULL, keeping only the A, B, C grades\n",
    "\n",
    "# \n",
    "df.GRADE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df['TO_DELETE'] |=  (df['INSPECTION_TYPE'] != 'Initial Inspection') & (df['SCORE'] < 14) & (df['GRADE'].isnull())\n",
    "df['TO_DELETE'] |=  (df.GRADE=='Z')\n",
    "df['TO_DELETE'] |=  (df.GRADE=='P')\n",
    "df['TO_DELETE'] |=  (df.GRADE=='Not Yet Graded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### GRADE_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df[\"GRADE_DATE\"] = pd.to_datetime(df[\"GRADE_DATE\"], format=\"%m/%d/%Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Grade date and inspection date should be the same. \n",
    "assert np.abs((df.GRADE_DATE - df.INSPECTION_DATE).dropna()).sum().days == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Check that is there is a grade date, a grade is also assigned\n",
    "assert sum ( ~df.GRADE_DATE.isnull() & df.GRADE.isnull() )  == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# We do not need GRADE DATE if we have INSPECTION DATE\n",
    "df = df.drop(\"GRADE_DATE\", axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### VIOLATION_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# In the dataset we have a NULL violation, when there is no violation\n",
    "# To make this more explicit, we replace NULL with 000\n",
    "df.VIOLATION_CODE.fillna('000', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### MISC analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Find the unique values in each column\n",
    "# \n",
    "# df.describe(include = [np.object, 'category']).T['unique']\n",
    "unique = df.describe(include = 'all').T['unique'].sort_values()\n",
    "\n",
    "for column in unique.index:\n",
    "    if unique[column] < 200:\n",
    "        print(df[column].value_counts())\n",
    "        print(\"=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Deleting Entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "In this section, we use the results of the analysis above, and delete (additional) entries that will not be useful in our analysis. (Note that it is important to document this, as others may want to go back to the original source, if the entries that we leave are not sufficient.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "assert len(df) == initial_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df = df[ df.TO_DELETE == False].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "\n",
    "\n",
    "assert sum(df.INSPECTION_TYPE.isnull()) == 0\n",
    "\n",
    "assert len(set(df.INSPECTION_TYPE.values)) == 2\n",
    "\n",
    "df[\"INSPECTION_TYPE\"] =  pd.Categorical(df[\"INSPECTION_TYPE\"], ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Check that no borough entries are empty\n",
    "assert sum(df.BORO.isnull()) == 0\n",
    "\n",
    "df[\"BORO\"] =  pd.Categorical(df[\"BORO\"], ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Check that no street numbers are empty\n",
    "assert sum(df.BUILDING.isnull()) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "assert sum(df.STREET.isnull()) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "\n",
    "assert sum(df.CUISINE_DESCRIPTION.isnull()) == 0\n",
    "\n",
    "df[\"CUISINE_DESCRIPTION\"] =  pd.Categorical(df[\"CUISINE_DESCRIPTION\"], ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# We only keep three different actions\n",
    "assert len(set(df.ACTION.values)) == 3\n",
    "\n",
    "# No action is empty\n",
    "assert sum(df.ACTION.isnull()) == 0\n",
    "\n",
    "df[\"ACTION\"] =  pd.Categorical(df[\"ACTION\"], ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# The below drops any grade values other than A, B, C, and converts the remaining entries to null\n",
    "df[\"GRADE\"] =  pd.Categorical(df[\"GRADE\"], categories = ['A', 'B', 'C'], ordered=True)\n",
    "\n",
    "# https://www1.nyc.gov/assets/doh/downloads/pdf/rii/how-we-score-grade.pdf\n",
    "# 0-13 get an A\n",
    "assert sum( (df.GRADE=='A') & (df.SCORE>13)) == 0\n",
    "\n",
    "# 14-27 get a B\n",
    "assert sum( (df.GRADE=='B') & ( (df.SCORE<14) | (df.SCORE>27) ) ) == 0\n",
    "\n",
    "# 28- get a C\n",
    "assert sum( (df.GRADE=='C') & (df.SCORE<28) ) == 0\n",
    "\n",
    "# In principle, a NULL grade is only when the score is above 14, and it was an initial inspection\n",
    "assert sum( (df['INSPECTION_TYPE'] != 'Initial Inspection') & (df['SCORE'] < 14) & (df['GRADE'].isnull()) ) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Check that is there is a grade date, a grade is also assigned\n",
    "# assert sum ( ~df.GRADE_DATE.isnull() & df.GRADE.isnull() ) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df[\"VIOLATION_CODE\"] =  pd.Categorical(df[\"VIOLATION_CODE\"], ordered=False)\n",
    "df[\"CRITICAL_FLAG\"] =  pd.Categorical(df[\"CRITICAL_FLAG\"], ordered=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Violation Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Recreating the table at https://www1.nyc.gov/assets/doh/downloads/pdf/rii/ri-violation-penalty.pdf\n",
    "\n",
    "violation_codes = df [ ['VIOLATION_CODE', 'VIOLATION_DESCRIPTION', 'CRITICAL_FLAG'] ].drop_duplicates()\n",
    "violation_codes = violation_codes.rename( {\n",
    "    'VIOLATION_DESCRIPTION' : 'DESCRIPTION',\n",
    "    'CRITICAL_FLAG' : 'CRITICAL'\n",
    "},  axis = 'columns').sort_values('VIOLATION_CODE').set_index('VIOLATION_CODE')#.drop(np.nan)\n",
    "violation_codes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Drop the description and critical part from the main dataframe\n",
    "df = df.drop(['VIOLATION_DESCRIPTION' ,  'CRITICAL_FLAG'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "restaurants =  df [ ['CAMIS', 'DBA', 'BUILDING', 'STREET', 'ZIPCODE', 'BORO', 'PHONE', 'CUISINE_DESCRIPTION', 'Latitude', 'Longitude'] ].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Check that we have the same attributes for a given CAMIS\n",
    "# and the we do not have duplicate CAMIS values\n",
    "assert len(restaurants) == len(set(restaurants.CAMIS.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# TODO: Pass the addresses through Google Maps API and get the x and y coordinates and fix zipcodes etc\n",
    "\n",
    "restaurants.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "restaurants.PHONE.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# __ = restaurants.PHONE.value_counts().head(10).index.values[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# restaurants.PHONE.replace(to_replace=__, value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Citi Field concessions\n",
    "# restaurants.query(\"PHONE == '7185958100'\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# Madison Square Garden concession stands\n",
    "# restaurants.query(\"PHONE == '2124656273'\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "restaurants.DBA.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df = df.drop (['DBA', 'BUILDING', 'STREET', 'ZIPCODE', 'BORO', 'PHONE', 'CUISINE_DESCRIPTION'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Each inspection has multiple violations. We want to keep just the inspections for now\n",
    "inspection = df.drop('VIOLATION_CODE', axis='columns').drop_duplicates().sort_values(['INSPECTION_DATE', 'CAMIS'])\n",
    "inspection = inspection.drop(['TO_DELETE'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# We create an ID for each inspection here\n",
    "inspection = inspection.reset_index().drop('index', axis='columns').reset_index().rename({'index': 'INSPECTION_ID'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "inspection.ACTION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Ensure that the inspection table contains \n",
    "# no duplicate pairs for 'INSPECTION_DATE', 'CAMIS'\n",
    "pvt = inspection.pivot_table(\n",
    "    index = ['INSPECTION_DATE', 'CAMIS'],\n",
    "    values = 'INSPECTION_ID',\n",
    "    aggfunc = 'count'\n",
    ")\n",
    "pvt [ pvt.INSPECTION_ID > 1 ]\n",
    "\n",
    "# assert len(pvt [ pvt.INSPECTION_ID > 1 ]) == 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# df[ (df.CAMIS =='41007054') & (df.INSPECTION_DATE == '2017-03-03')  ].sort_values('VIOLATION_CODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# df[ (df.CAMIS =='50048062') & (df.INSPECTION_DATE == '2018-10-30')  ].sort_values('VIOLATION_CODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "df[ (df.CAMIS =='40911114') & (df.INSPECTION_DATE == '2017-11-04')  ].sort_values('VIOLATION_CODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# df[ (df.CAMIS =='41485450') & (df.INSPECTION_DATE == '2018-04-12')  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "inspection.INSPECTION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "inspection_stats = inspection.pivot_table(\n",
    "    index = 'CAMIS',\n",
    "    aggfunc = ['min', 'max', 'count'],\n",
    "    values = 'INSPECTION_DATE'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Distribution of last inspection across all restaurants\n",
    "inspection_stats['max'].sort_values('INSPECTION_DATE').reset_index().pivot_table(\n",
    "    index='INSPECTION_DATE',\n",
    "    aggfunc='count'\n",
    ").resample('1W').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Longevity \n",
    "# (inspection_stats['max'] - inspection_stats['min'])['INSPECTION DATE'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Distribution of all inspections\n",
    "inspection['INSPECTION_DATE'].value_counts().sort_index().resample('1W').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "violations = pd.merge(\n",
    "    inspection,\n",
    "    df[ ['CAMIS', 'INSPECTION_DATE', 'VIOLATION_CODE' ] ],\n",
    "    on= ['CAMIS', 'INSPECTION_DATE'],\n",
    "    how = 'inner'\n",
    ")\n",
    "violations = violations[ ['INSPECTION_ID', 'VIOLATION_CODE'] ].drop_duplicates()\n",
    "len(violations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "inspection = inspection.drop(\n",
    "        [\n",
    "            'Longitude', 'Latitude', 'Community_Board', 'Council_District', 'Census_Tract', 'BIN', 'BBL', 'NTA'\n",
    "        ], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "print(f\"Violations: {len(violations)}\")\n",
    "print(f\"Inspections: {len(inspection)}\")\n",
    "print(f\"Restaurants: {len(restaurants)}\")\n",
    "print(f\"Violation Codes: {len(violation_codes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Geocoding restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "import requests\n",
    "def call_google_api(address):\n",
    "    \n",
    "    # API key from 'ipeirotis' project. Limited to be called only from ipython.ipeirotis.com\n",
    "    # We need a different key for Travis or other setting\n",
    "    GOOGLE_MAPS_API_URL = 'https://maps.googleapis.com/maps/api/geocode/json' \n",
    "    params = {\n",
    "        'address': address,\n",
    "        'key' : 'INSERT-KEY',\n",
    "        'region': 'INSERT-REGION'\n",
    "    }\n",
    "    req = requests.get(GOOGLE_MAPS_API_URL, params=params)\n",
    "    \n",
    "    results = req.json()\n",
    "\n",
    "    \n",
    "    # Use the first result\n",
    "    if 'results' in results and len(results['results'])>0:\n",
    "        result = results['results'][0]\n",
    "        return result\n",
    "    else:\n",
    "        # Something went wrong\n",
    "        print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "def parse(data):\n",
    "    # x = pd.DataFrame(google_result['address_components']).long_name.values\n",
    "    # lng = x[0] + ' ' + x[1] + ', ' + x[2] + ', ' + x[3] + ', ' + x[4] + ', ' + x[5] + ', ' + x[7] + '-' + x[8] \n",
    "    \n",
    "    zipcode = [element['long_name'] for element in data['address_components'] if 'postal_code' in element['types']]\n",
    "    country = [element['long_name'] for element in data['address_components'] if 'country' in element['types']]\n",
    "    state   = [element['short_name'] for element in data['address_components'] if 'administrative_area_level_1' in element['types']]\n",
    "    borough    = [element['short_name'] for element in data['address_components'] if 'sublocality_level_1' in element['types']]\n",
    "    street = [element['long_name'] for element in data['address_components'] if 'route' in element['types']]\n",
    "    street_num = [element['long_name'] for element in data['address_components'] if 'street_number' in element['types']]\n",
    "    \n",
    "    \n",
    "    result = dict()\n",
    "    result[\"formatted_address\"] = data['formatted_address']\n",
    "    result[\"lon\"] = data['geometry']['location']['lng']\n",
    "    result[\"lat\"] = data['geometry']['location']['lat']\n",
    "    result[\"zipcode\"] = zipcode[0] if len(zipcode)>0 else None\n",
    "    result[\"country\"] = country[0] if len(country)>0 else None\n",
    "    result[\"state\"]   = state[0] if len(state)>0 else None\n",
    "    result[\"borough\"]    = borough[0] if len(borough)>0 else None\n",
    "    result[\"street\"]    = street[0] if len(street)>0 else None\n",
    "    result[\"street_num\"]    = street_num[0] if len(street_num)>0 else None\n",
    "    if 'plus_code' in data:\n",
    "        result['plus_code'] = data['plus_code']['global_code']\n",
    "    \n",
    "    return result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import gzip    \n",
    "\n",
    "def load_cache():\n",
    "    with gzip.open('geocoding.json.gz', 'rb') as fp:\n",
    "        json_bytes = fp.read()\n",
    "        data = json.loads(json_bytes.decode('utf-8'))\n",
    "    return data\n",
    "\n",
    "def update_cache(restaurants, cache):\n",
    "\n",
    "    for index, row in tqdm(restaurants.iterrows(), total=restaurants.shape[0]):\n",
    "\n",
    "        # If we already have the result in cache, skip querying the Google Maps API\n",
    "        if row.CAMIS in cache:\n",
    "            continue\n",
    "\n",
    "        # Query first with the name of the restaurant\n",
    "        address = row.DBA + ', ' + row.BUILDING + ' ' + row.STREET + ', ' + row.BORO + ' ' + (row.ZIPCODE if type(row.ZIPCODE)==str  else \"\")\n",
    "        google_result = call_google_api(address)\n",
    "\n",
    "         # If we do not get an answer with the restaurant name, query just with the address\n",
    "        if google_result == None:\n",
    "            address = row.BUILDING + ' ' + row.STREET + ', ' + row.BORO + ' ' + (row.ZIPCODE if type(row.ZIPCODE)==str  else \"\")\n",
    "            google_result = call_google_api(address)\n",
    "\n",
    "        # If still none, then skip\n",
    "        if google_result == None:\n",
    "            continue\n",
    "\n",
    "        cache[row.CAMIS] = google_result\n",
    "        \n",
    "    # Remove geocoding results that we do not need anymore\n",
    "    notneeded = set(cache.keys()) - set(restaurants.CAMIS.values) \n",
    "    for n in notneeded:\n",
    "        del cache[n]\n",
    "        \n",
    "    return cache\n",
    "     \n",
    "def write_cache(data):\n",
    "    json_bytes = json.dumps(data, sort_keys=True, indent=4).encode('utf-8')  \n",
    "    with gzip.open('geocoding.json.gz', 'wb') as fp:\n",
    "        fp.write(json_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "#cache = load_cache()\n",
    "#cache = update_cache(restaurants, cache)\n",
    "#write_cache(cache)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "#nogoogle = set(restaurants.CAMIS.values) - set(cache.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "#len(nogoogle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "#restaurants [ restaurants.CAMIS.isin(nogoogle) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# result = []\n",
    "# for camis in restaurants.CAMIS.values:\n",
    "#     g = cache[camis]\n",
    "#     # print(camis)\n",
    "#     f = parse(g)\n",
    "#     f['camis'] = camis\n",
    "#     result.append(f)\n",
    "    \n",
    "# zdf = pd.DataFrame(result)\n",
    "# zdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# zdf[zdf.zipcode.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# zdf = zdf[zdf.state == 'NY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# zdf[ ~zdf.borough.isin(['Manhattan', 'Queens', 'Bronx', 'Brooklyn', 'Staten Island'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# zdf = zdf[zdf.lat<41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "inspection.query( \" CAMIS == '41480442' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "borough = 'Queens'\n",
    "\n",
    "shapefile_url = 'https://data.cityofnewyork.us/api/geospatial/cpf4-rkhq?method=export&format=Shapefile'\n",
    "df_nyc = gpd.GeoDataFrame.from_file(shapefile_url)\n",
    "\n",
    "base = df_nyc[df_nyc.boro_name==borough].plot(\n",
    "    linewidth=0.5,\n",
    "    color='White',\n",
    "    edgecolor='Black',\n",
    "    figsize=(15, 20),\n",
    "    alpha=0.75)\n",
    "\n",
    "scatterplot = zdf[zdf.borough==borough].plot(\n",
    "    kind='scatter',\n",
    "    x='lon',\n",
    "    y='lat',\n",
    "    s=2,\n",
    "    c='g',\n",
    "    alpha=0.4,\n",
    "    ax=base)\n",
    "\n",
    "\n",
    "sns.kdeplot(\n",
    "    zdf[zdf.borough==borough].lon,\n",
    "    zdf[zdf.borough==borough].lat,\n",
    "    gridsize=200,\n",
    "    n_levels=25,\n",
    "    shade=True,\n",
    "    alpha=0.3,\n",
    "    cmap=plt.cm.coolwarm,\n",
    "    shade_lowest=False,\n",
    "    ax=scatterplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Store final data to databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Function to save the data to a MySQL or a SQLite table.\n",
    "def addToTable(engine, db_name, table, data, useIndex=False):\n",
    "    batchsize = 50000\n",
    "    batches = len(data) // batchsize + 1\n",
    "\n",
    "    t = tqdm(range(batches))\n",
    "\n",
    "    if db_name == \"\":\n",
    "        for i in t:\n",
    "            # print(\"Batch:\",i)\n",
    "            # continue # Cannot execute this on Travis\n",
    "            start = batchsize * i\n",
    "            end = batchsize * (i+1)\n",
    "            data[start:end].to_sql(\n",
    "                name = table,\n",
    "                con = engine,\n",
    "                if_exists = 'append',\n",
    "                index = useIndex,\n",
    "                chunksize = 1000)\n",
    "    else:\n",
    "        for i in t:\n",
    "            # print(\"Batch:\",i)\n",
    "            # continue # Cannot execute this on Travis\n",
    "            start = batchsize * i\n",
    "            end = batchsize * (i+1)\n",
    "            data[start:end].to_sql(\n",
    "                name = table,\n",
    "                schema = db_name,\n",
    "                con = engine,\n",
    "                if_exists = 'append',\n",
    "                index = useIndex,\n",
    "                chunksize = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# Create link with username, password and hostname to connect to database\n",
    "conn_string = 'mysql://{user}:{password}@{host}/?charset={encoding}'.format(\n",
    "host = 'localhost', \n",
    "user = 'root',\n",
    "password = 'root',\n",
    "encoding = 'utf8mb4')\n",
    "# Create engine to connect to mySQL\n",
    "engine = create_engine(conn_string)\n",
    "con = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "db_name = 'restaurant_inspections'\n",
    "charset = 'utf8mb4'\n",
    "# Drop previous outdated database\n",
    "sql = f'DROP DATABASE IF EXISTS {db_name}'\n",
    "engine.execute(sql)\n",
    "# Create Database restaurant_inspections\n",
    "sql = f'CREATE DATABASE IF NOT EXISTS {db_name} DEFAULT CHARACTER SET {charset}'\n",
    "engine.execute(sql)\n",
    "\n",
    "sql = f'USE {db_name}'\n",
    "engine.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "critical_categories = list(violation_codes.CRITICAL.cat.categories)\n",
    "critical_categories = '\\'' + ('\\', \\''.join(critical_categories)) + '\\''\n",
    "# Create Violation Codes Table\n",
    "violationCodesTable = \"\"\"\n",
    "CREATE TABLE ViolationCodes (\n",
    "    VIOLATION_CODE varchar(3) PRIMARY KEY,\n",
    "    DESCRIPTION text,\n",
    "    CRITICAL enum(\"\"\" + critical_categories + \"\"\")\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\"\"\"\n",
    "engine.execute(violationCodesTable)\n",
    "# Save violations codes to table\n",
    "addToTable(engine, db_name, table='ViolationCodes', data=violation_codes, useIndex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "cuisine_description_categories = list(restaurants.CUISINE_DESCRIPTION.cat.categories)\n",
    "cuisine_description_categories = '\\'' + ('\\', \\''.join(cuisine_description_categories)) + '\\''\n",
    "boro_categories = list(restaurants.BORO.cat.categories)\n",
    "boro_categories = '\\'' + ('\\', \\''.join(boro_categories)) + '\\''\n",
    "# Create Restaurants Table\n",
    "restaurantsTable = \"\"\"\n",
    "CREATE TABLE Restaurants (\n",
    "    CAMIS int(9) unsigned PRIMARY KEY,\n",
    "    DBA tinytext,\n",
    "    BUILDING varchar(10),\n",
    "    STREET tinytext,\n",
    "    ZIPCODE int(6) unsigned,\n",
    "    BORO enum(\"\"\" + boro_categories + \"\"\"),\n",
    "    PHONE varchar(11),\n",
    "    CUISINE_DESCRIPTION enum(\"\"\" + cuisine_description_categories + \"\"\"),\n",
    "    Latitude double,\n",
    "    Longitude double\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\"\"\"\n",
    "engine.execute(restaurantsTable)\n",
    "# Add Restaurant data to Restaurants Table\n",
    "addToTable(engine, db_name, table='Restaurants', data=restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Create Inspections Table\n",
    "inspectionTable = \"\"\"\n",
    "CREATE TABLE Inspections (\n",
    "    INSPECTION_ID int PRIMARY KEY,\n",
    "    CAMIS int(9) unsigned NOT NULL,\n",
    "    INSPECTION_DATE Date,\n",
    "    ACTION enum('Establishment closed', 'No violations', 'Violations found'),\n",
    "    SCORE float,\n",
    "    GRADE enum('A','B','C'),\n",
    "    GRADE_DATE Date,\n",
    "    RECORD_DATE Date,\n",
    "    INSPECTION_TYPE enum('Initial Inspection', 'Re-inspection'),\n",
    "    FOREIGN KEY (CAMIS) REFERENCES Restaurants(CAMIS)\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\"\"\"\n",
    "engine.execute(inspectionTable)\n",
    "# Save inspecton data to Inspections Table\n",
    "addToTable(engine, db_name, table='Inspections', data=inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Create Violations Table\n",
    "violationsTable = \"\"\"\n",
    "CREATE TABLE Violations (\n",
    "    INSPECTION_ID int,\n",
    "    VIOLATION_CODE varchar(3),\n",
    "    PRIMARY KEY (INSPECTION_ID, VIOLATION_CODE),\n",
    "    FOREIGN KEY (INSPECTION_ID) REFERENCES Inspections(INSPECTION_ID),\n",
    "    FOREIGN KEY (VIOLATION_CODE) REFERENCES ViolationCodes(VIOLATION_CODE)\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\"\"\"\n",
    "engine.execute(violationsTable)\n",
    "# Save violation data to Violations Table\n",
    "addToTable(engine, db_name, table='Violations', data=violations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Close our connection to the MySQL database\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Before saving data to SQLite we first delete the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "!rm restaurant_inspections.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "import sqlite3\n",
    "# Create and connect to the SQLite database\n",
    "db_name = 'restaurant_inspections.db'\n",
    "con = sqlite3.connect(db_name)\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Create Violation Codes Table\n",
    "violationCodesTable = \"\"\"\n",
    "CREATE TABLE ViolationCodes (\n",
    "    VIOLATION_CODE varchar(3) PRIMARY KEY,\n",
    "    DESCRIPTION text,\n",
    "    CRITICAL text\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(violationCodesTable)\n",
    "# Save violation codes to database\n",
    "addToTable(con, db_name, table='ViolationCodes', data=violation_codes, useIndex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Create Restaurants Table\n",
    "restaurantsTable = \"\"\"\n",
    "CREATE TABLE Restaurants (\n",
    "    CAMIS int unsigned PRIMARY KEY,\n",
    "    DBA varchar(150),\n",
    "    BUILDING varchar(10),\n",
    "    STREET varchar(150),\n",
    "    ZIPCODE int unsigned,\n",
    "    BORO varchar(20),\n",
    "    PHONE varchar(11),\n",
    "    CUISINE_DESCRIPTION varchar(20),\n",
    "    Latitude double,\n",
    "    Longitude double\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(restaurantsTable)\n",
    "# Save restaurants data to Restaurants Table\n",
    "addToTable(con, db_name, table='Restaurants', data=restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Create Inspections Table\n",
    "inspectionTable = \"\"\"\n",
    "CREATE TABLE Inspections (\n",
    "    INSPECTION_ID int PRIMARY KEY,\n",
    "    CAMIS int NOT NULL,\n",
    "    INSPECTION_DATE Date,\n",
    "    ACTION varchar(20),\n",
    "    SCORE float,\n",
    "    GRADE nchar(1),\n",
    "    GRADE_DATE Date,\n",
    "    RECORD_DATE Date,\n",
    "    INSPECTION_TYPE varchar(20)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(inspectionTable)\n",
    "# Save inspection data to Inspections Table\n",
    "addToTable(con, db_name, table='Inspections', data=inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Create Violations Table\n",
    "violationsTable = \"\"\"\n",
    "CREATE TABLE Violations (\n",
    "    INSPECTION_ID int,\n",
    "    VIOLATION_CODE varchar(3),\n",
    "    PRIMARY KEY (INSPECTION_ID, VIOLATION_CODE)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(violationsTable)\n",
    "# Save violations data to Violations Table\n",
    "addToTable(con, db_name, table='Violations', data=violations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Make sure the changes to the database have been saved\n",
    "con.commit()\n",
    "# Close connection to the SQLite database\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "violation_codes.to_csv('violationCodes.csv.gz', index=True, compression=\"gzip\")\n",
    "restaurants.to_csv('restaurantsTable.csv.gz', index=False, compression=\"gzip\")\n",
    "inspection.to_csv('inspections.csv.gz', index=False, compression=\"gzip\")\n",
    "violations.to_csv('violations.csv.gz', index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Exercise: Figure out the typical points for violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# Trying to figure out the costliest violations\n",
    "# Here is the guide, which explains that \n",
    "# https://www1.nyc.gov/assets/doh/downloads/pdf/rii/how-we-score-grade.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "scores = pd.DataFrame(inspection [ ~inspection.SCORE.isnull() ].set_index('INSPECTION_ID').SCORE)\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "join = violations = pd.merge(\n",
    "    inspection,\n",
    "    df[ ['CAMIS', 'INSPECTION_DATE', 'VIOLATION_CODE' ] ],\n",
    "    on= ['CAMIS', 'INSPECTION_DATE'],\n",
    "    how = 'inner'\n",
    ")[ ['INSPECTION_ID', 'VIOLATION_CODE', 'SCORE'] ]\n",
    "join.head()\n",
    "len(join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "wide_violations = join [ ~join.SCORE.isnull() ].pivot_table(\n",
    "    index = 'INSPECTION_ID',\n",
    "    columns = 'VIOLATION_CODE',\n",
    "    values = 'SCORE',\n",
    "    aggfunc = 'count'\n",
    ").fillna(0)\n",
    "\n",
    "wide_violations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "dataset = pd.merge(\n",
    "    scores, wide_violations, how='inner', left_index=True, right_index=True\n",
    ")\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "Y = dataset.SCORE.values\n",
    "X = dataset.drop('SCORE', axis='columns').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# cols = dataset.columns\n",
    "# cols = cols.map(lambda x : 'V'+x if x!='SCORE' else x)\n",
    "# dataset.columns = cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "from statsmodels.formula.api import ols, rlm\n",
    "# ols_model = ols('SCORE ~ V00 + V02A + V02B + V02C + V02D + V02E + V02F + V02G + V02H -1', dataset).fit()\n",
    "# ols_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# points = pd.DataFrame(violation_codes)\n",
    "violation_codes[\"POINTS\"] = results.params\n",
    "violation_codes = violation_codes.sort_values('POINTS', ascending=False)\n",
    "violation_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "# A quick exposure to various options of the \"hist\" command \n",
    "ax = inspection.SCORE.hist(bins=50, # use 50 bars\n",
    "                          range=(0,50), # x-axis from 0 to 50\n",
    "                          density=False,  # show normalized count (density=True), or raw counts (density= False)\n",
    "                          figsize=(10,5), # controls the size of the plot\n",
    "                          alpha = 0.8 # make the plot 20% transparent\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Inspection Score\")\n",
    "ax.set_ylabel(\"Number of Inspections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "inspection.CAMIS.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "restaurants.set_index('CAMIS').loc['41311804']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "restaurants.set_index('CAMIS').loc['41178236']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
   ],
   "source": [
    "inspection.query(' CAMIS == \"50035784\" ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "violation_codes.index.name = violation_codes.index.name.lower()\n",
    "violation_codes.columns = map(str.lower, violation_codes.columns)\n",
    "restaurants.columns = map(str.lower, restaurants.columns)\n",
    "inspection.columns = map(str.lower, inspection.columns)\n",
    "violations.columns = map(str.lower, violations.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "conn_string = 'postgresql://{user}:{password}@{host}:{port}/restaurant_inspections'.format(\n",
    "    host = cfg.postgres_host, \n",
    "    user = cfg.postgres_user,\n",
    "    password = cfg.postgres_pass,\n",
    "    port = cfg.postgres_port\n",
    ")\n",
    "\n",
    "engine = create_engine(conn_string)\n",
    "con = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "engine.execute('DROP TABLE IF EXISTS violations')\n",
    "engine.execute('DROP TABLE IF EXISTS inspections')\n",
    "engine.execute('DROP TABLE IF EXISTS violation_codes')\n",
    "engine.execute('DROP TABLE IF EXISTS restaurants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "violationCodesTable = \"\"\"\n",
    "CREATE TABLE violation_codes (\n",
    "    violation_code varchar(3) PRIMARY KEY,\n",
    "    description text,\n",
    "    critical critical_enum\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "critical_categories = list(violation_codes.critical.cat.categories)\n",
    "critical_categories = '\\'' + ('\\', \\''.join(critical_categories)) + '\\''\n",
    "engine.execute('DROP TYPE IF EXISTS critical_enum')\n",
    "engine.execute(\"CREATE TYPE critical_enum AS ENUM(\" + critical_categories +\")\")\n",
    "engine.execute(violationCodesTable)\n",
    "\n",
    "addToTable(engine, \"\", table='violation_codes', data=violation_codes, useIndex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "restaurantsTable = \"\"\"\n",
    "CREATE TABLE restaurants (\n",
    "    camis int PRIMARY KEY,\n",
    "    dba text,\n",
    "    building varchar(10),\n",
    "    street text,\n",
    "    zipcode int,\n",
    "    boro boro_enum,\n",
    "    phone varchar(11),\n",
    "    cuisine_description cuisine_description_enum,\n",
    "    latitude double precision,\n",
    "    longitude double precision\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cuisine_description_categories = list(restaurants.cuisine_description.cat.categories)\n",
    "cuisine_description_categories = '\\'' + ('\\', \\''.join(cuisine_description_categories)) + '\\''\n",
    "boro_categories = list(restaurants.boro.cat.categories)\n",
    "boro_categories = '\\'' + ('\\', \\''.join(boro_categories)) + '\\''\n",
    "engine.execute('DROP TYPE IF EXISTS boro_enum')\n",
    "engine.execute('DROP TYPE IF EXISTS cuisine_description_enum')\n",
    "engine.execute(\"CREATE TYPE boro_enum AS ENUM(\" + boro_categories + \")\")\n",
    "engine.execute(\"CREATE TYPE cuisine_description_enum AS ENUM(\" + cuisine_description_categories + \")\")\n",
    "engine.execute(restaurantsTable)\n",
    "\n",
    "addToTable(engine, \"\", table='restaurants', data=restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "inspectionTable = \"\"\"\n",
    "CREATE TABLE inspections (\n",
    "    inspection_id int PRIMARY KEY,\n",
    "    camis int NOT NULL,\n",
    "    inspection_date Date,\n",
    "    action action_enum,\n",
    "    score float,\n",
    "    grade grade_enum,\n",
    "    grade_date Date,\n",
    "    record_date Date,\n",
    "    inspection_type inspection_type_enum,\n",
    "    FOREIGN KEY (camis) REFERENCES restaurants(camis)\n",
    ");\n",
    "\"\"\"\n",
    "engine.execute('DROP TYPE IF EXISTS action_enum')\n",
    "engine.execute('DROP TYPE IF EXISTS inspection_type_enum')\n",
    "engine.execute('DROP TYPE IF EXISTS grade_enum')\n",
    "engine.execute(\"CREATE TYPE action_enum AS ENUM('Establishment closed', 'No violations', 'Violations found')\")\n",
    "engine.execute(\"CREATE TYPE inspection_type_enum AS ENUM('Initial Inspection', 'Re-inspection')\")\n",
    "engine.execute(\"CREATE TYPE grade_enum AS ENUM('A','B','C')\")\n",
    "engine.execute(inspectionTable)\n",
    "\n",
    "addToTable(engine, \"\", table='inspections', data=inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "violationsTable = \"\"\"\n",
    "CREATE TABLE violations (\n",
    "    inspection_id int,\n",
    "    violation_code varchar(3),\n",
    "    PRIMARY KEY (inspection_id, violation_code),\n",
    "    FOREIGN KEY (inspection_id) REFERENCES inspections(inspection_id),\n",
    "    FOREIGN KEY (violation_code) REFERENCES violation_codes(violation_code)\n",
    ");\n",
    "\"\"\"\n",
    "engine.execute(violationsTable)\n",
    "\n",
    "addToTable(engine, \"\", table='violations', data=violations)\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Testing\n",
    "This part of the script is used to validate the integrity \n",
    "of the incoming dataset and point out inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def init():\n",
    "    # configure logging\n",
    "    logger = logging.getLogger()\n",
    "    handler = logging.FileHandler('.log','w')\n",
    "    formatter = logging.Formatter('[%(asctime)s] %(levelname)-8s %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def readCSV():\n",
    "    logging.info('Reading CSV...')\n",
    "    return pd.read_csv('restaurants.csv.gz', dtype = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def fixIndeces(data):\n",
    "    # Adding underscores in all column names\n",
    "    data.columns = data.columns.map(lambda x: x.replace(' ', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def checkColumns(data):\n",
    "    errors = False\n",
    "    logging.info('***Checking if any columns have benn removed or added to the dataset.***')\n",
    "    # Check if all columns needed are in the dataset\n",
    "    VALUES = ['INSPECTION_TYPE','CUISINE_DESCRIPTION','INSPECTION_DATE',\n",
    "    'ACTION','SCORE','RECORD_DATE','GRADE','GRADE_DATE','VIOLATION_CODE',\n",
    "    'BORO','BUILDING','STREET','CRITICAL_FLAG','VIOLATION_DESCRIPTION',\n",
    "    'CAMIS', 'DBA', 'ZIPCODE', 'PHONE', 'Latitude', 'Longitude','Community_Board', \n",
    "    'Council_District', 'Census_Tract', 'BIN', 'BBL','NTA']\n",
    "    sortedInput = list(data.columns)\n",
    "    sortedInput.sort()\n",
    "    VALUES.sort()\n",
    "    if (VALUES != sortedInput):\n",
    "        added = set(sortedInput).difference(VALUES)\n",
    "        removed = set(VALUES).difference(sortedInput)\n",
    "        logging.error('Inconsistency found...')\n",
    "        if (len(added) != 0):\n",
    "            logging.error('New columns added to the dataset: ' + str(added) + '.')\n",
    "        if (len(removed) != 0):\n",
    "            logging.error('Columns removed from the dataset: ' + str(removed) + '.')\n",
    "        errors = True\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def checkValues(data):\n",
    "    errors = False\n",
    "    logging.info('***Check the validity of the values of the dataset we use***')\n",
    "    testVals = ['Cycle Inspection / Initial Inspection', 'Cycle Inspection / Re-inspection']\n",
    "    errors |= testValues(data, 'INSPECTION_TYPE', testVals)\n",
    "    testVals = [\n",
    "        'Violations were cited in the following area(s).',\n",
    "        'No violations were recorded at the time of this inspection.',\n",
    "        'Establishment Closed by DOHMH.  Violations were cited in the following area(s) and those requiring immediate action were addressed.',\n",
    "        'Establishment re-opened by DOHMH',\n",
    "        'Establishment re-closed by DOHMH'\n",
    "    ]\n",
    "    errors |= testValues(data, 'ACTION', testVals)\n",
    "    testVals = ['A', 'B', 'C', 'G']\n",
    "    errors |= testValues(data, 'GRADE', testVals)\n",
    "\n",
    "    errors |= testDates(data, 'INSPECTION_DATE')\n",
    "    errors |= testDates(data, 'RECORD_DATE')\n",
    "    errors |= testDates(data, 'GRADE_DATE')\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def testColumn(data, column):\n",
    "    if not column in data.columns:\n",
    "        logging.error('Inconsistency found...')  \n",
    "        logging.error('Column \"%s\" does not exists' % (column))\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def testDates(data, column):\n",
    "    logging.info('Checking dates on column \"%s\"' % column)\n",
    "    if testColumn(data, column):\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        data[column] = pd.to_datetime(data[column], format='%m/%d/%Y')\n",
    "    except ValueError as er:\n",
    "        logging.error('Inconsistency found...')\n",
    "        logging.error('There are malformed date values in column \"%s\"' % (column))\n",
    "        logging.error(str(er))\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def testValues(data, column, values):\n",
    "    error = False\n",
    "    logging.info('Checking values on column \"%s\"' % column)\n",
    "    if testColumn(data, column):\n",
    "        return True\n",
    "\n",
    "    inspVals = data[column].values\n",
    "    for tval in values:\n",
    "        if not tval in inspVals:\n",
    "            logging.error('Inconsistency found...')  \n",
    "            logging.error('Value \"%s\" is not in column \"%s\"' % (tval, column))\n",
    "            error = True\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def main():\n",
    "    errors = False\n",
    "    init()\n",
    "    logging.info('Running Tests...')\n",
    "    df = readCSV()\n",
    "    fixIndeces(df)\n",
    "    errors |= checkColumns(df)\n",
    "    errors |= checkValues(df)\n",
    "    if errors:\n",
    "        logging.error('Errors found.')\n",
    "        logging.info('Exiting with error code 1.')\n",
    "        exit(1)\n",
    "    logging.info('No errors found.')\n",
    "    logging.info('Exiting...')\n",
    "\n",
    "# in order to execute the script you just need to call the main function\n",
    "# main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}