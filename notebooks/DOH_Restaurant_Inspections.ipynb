{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www1.nyc.gov/site/doh/business/food-operators/the-inspection-process.page\n",
    "\n",
    "See https://www1.nyc.gov/assets/doh/downloads/pdf/rii/blue-book.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install pandas-profiling[notebook]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Latest Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl 'https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD' -o restaurants.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"restaurants.csv\", dtype = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_size = len(df)\n",
    "initial_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render our plots inline\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding underscores in all column names\n",
    "cols = df.columns\n",
    "cols = cols.map(lambda x: x.replace(' ', '_').upper())\n",
    "df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Individual Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CAMIS.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DBA.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks that all CAMIS values correpond to a unique DBA value\n",
    "# ie the same CAMIS always has the same DBA\n",
    "max_cardinality = df[['DBA','CAMIS']].pivot_table(\n",
    "    index='CAMIS',\n",
    "    values='DBA',\n",
    "    aggfunc=pd.Series.nunique\n",
    ").DBA.max()\n",
    "\n",
    "assert(max_cardinality==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSPECTION_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.INSPECTION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.INSPECTION_TYPE.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a column \"TO_DELETE\" to mark the entries that we are not interested in.\n",
    "# We will perform first the inspection/analysis on all the attributes, and then delete the rows\n",
    "\n",
    "# Drop all cases where inspection is NULL\n",
    "df['TO_DELETE'] = df.INSPECTION_TYPE.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break INSPECTION_TYPE into two columns, and also delete some inspection types\n",
    "\n",
    "# Create a new column that contains the results of the split on the '/'' character\n",
    "lst = df.INSPECTION_TYPE.str.split(' / ').values.tolist()\n",
    "lst = [ l if type(l)==type(list()) else ['',''] for l in lst ]\n",
    "t = pd.DataFrame(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only cycle inspections. Ignore admin, pre-permit, transfat, and calorie posting inspections\n",
    "# We will only keep the initial inspections and the re-inspections. The other types are border cases\n",
    "\n",
    "keep = df.INSPECTION_TYPE.isin( ['Cycle Inspection / Initial Inspection', 'Cycle Inspection / Re-inspection'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many we will drop: ~keep means negation on the keep and summing up adds up the 'True'\n",
    "sum(~keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the \"not keep\" entries into the TO_DELETE\n",
    "\n",
    "# The |= operator is a shortcut for df['TO_DELETE'] = df['TO_DELETE'] | ~keep\n",
    "# We use the bit-OR operator (|), as we want to keep the existing deletions, and add the ones from the \n",
    "# additional condition\n",
    "df['TO_DELETE'] |= ~keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the two entries that we will keep into simpler values\n",
    "\n",
    "df[\"INSPECTION_TYPE\"].replace(\n",
    "    to_replace='Cycle Inspection / Initial Inspection',\n",
    "    value = 'Initial Inspection',\n",
    "    inplace=True\n",
    ")\n",
    "df[\"INSPECTION_TYPE\"].replace(\n",
    "    to_replace='Cycle Inspection / Re-inspection',\n",
    "    value = 'Re-inspection',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BORO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.BORO.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.BORO.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the \"Missing\" in BORO with null\n",
    "# df.BORO = df.BORO.replace('Missing', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = set(df[df.BORO.isnull()].CAMIS)\n",
    "# missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.BORO == '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the entries with null/missing BORO value\n",
    "# Not worth trying to fix.\n",
    "df['TO_DELETE'] |= (df.BORO == '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.BUILDING.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the entries with missing street number\n",
    "# df[df.BUILDING.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the violations listed without street number\n",
    "# Most are in train stations and in airports, but there\n",
    "# are a few others in 'regular' locations\n",
    "\n",
    "df['TO_DELETE'] |= df.BUILDING.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STREET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no street values are empty\n",
    "sum(df.STREET.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TO_DELETE'] |= df.STREET.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZIPCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.ZIPCODE.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df[df.ZIPCODE.isnull()].CAMIS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TO_DELETE'] |= df.ZIPCODE.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in the missing zip codes, perhaps with geocoding of the addresses\n",
    "# For now, we just drop the cases without ZIPCODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUISINE DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CUISINE_DESCRIPTION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.CUISINE_DESCRIPTION.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.CUISINE_DESCRIPTION.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CUISINE_DESCRIPTION.replace(\n",
    "    to_replace='Café/Coffee/Tea',\n",
    "    value = 'Cafe',\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "df.CUISINE_DESCRIPTION.replace(\n",
    "    to_replace='Latin (Cuban, Dominican, Puerto Rican, South & Central American)',\n",
    "    value = 'Latin',\n",
    "    inplace=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSPECTION_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"INSPECTION_DATE\"] = pd.to_datetime(df[\"INSPECTION_DATE\"], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.INSPECTION_DATE.describe(datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.INSPECTION_DATE.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.INSPECTION_DATE.hist(range=(pd.to_datetime('2010-01-01'),pd.to_datetime('2014-12-31')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 1900-01-01 inspections. These are all incorrect and we cannot fix them\n",
    "df['TO_DELETE'] |= (df['INSPECTION_DATE'] == '1900-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After analysis, it seems that we have minimal number of inspections before 2015\n",
    "df['TO_DELETE'] |=  (df['INSPECTION_DATE'] < '2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.ACTION.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ACTION\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ACTION\"].replace(\n",
    "    to_replace='Violations were cited in the following area(s).',\n",
    "    value = 'Violations found',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ACTION\"].replace(\n",
    "    to_replace='No violations were recorded at the time of this inspection.',\n",
    "    value = 'No violations',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ACTION\"].replace(\n",
    "    to_replace='Establishment Closed by DOHMH.  Violations were cited in the following area(s) and those requiring immediate action were addressed.',\n",
    "    value = 'Establishment closed',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ACTION\"].replace(\n",
    "    to_replace='Establishment re-opened by DOHMH',\n",
    "    value = 'Establishment re-opened',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ACTION\"].replace(\n",
    "    to_replace='Establishment re-closed by DOHMH',\n",
    "    value = 'Establishment re-closed',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ACTION\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Establishment re-opened and re-closed cases\n",
    "# as the inspection scores for these can be misleading\n",
    "df['TO_DELETE'] |=  (df.ACTION == 'Establishment re-closed')\n",
    "df['TO_DELETE'] |=  (df.ACTION == 'Establishment re-opened')\n",
    "df['TO_DELETE'] |=  df.ACTION.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SCORE\"] = pd.to_numeric(df[\"SCORE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SCORE.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( df[ df.SCORE < 0 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TO_DELETE'] |= (df.SCORE < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop cases reported as \"no violations but with positive score\"\n",
    "df['TO_DELETE'] |= ((df.SCORE > 0)  & (df.ACTION == 'No violations'))\n",
    "\n",
    "# Drop cases with zero score but with violations found\n",
    "df['TO_DELETE'] |= ((df.SCORE == 0)  & (df.ACTION == 'Violations found'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop incorrectly scored inspections\n",
    "df['TO_DELETE'] |=  (df.GRADE=='A') & (df.SCORE>13)\n",
    "\n",
    "df['TO_DELETE'] |=  (df.GRADE=='B') & ( (df.SCORE<14) | (df.SCORE>27) )\n",
    "\n",
    "# Drop incorrectly scored inspections\n",
    "df['TO_DELETE'] |=  (df.GRADE=='C') & (df.SCORE<28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['TO_DELETE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECORD_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"RECORD_DATE\"] = pd.to_datetime(df[\"RECORD_DATE\"], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop record date field, as it only contains a single value\n",
    "df = df.drop( 'RECORD_DATE', axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.GRADE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.GRADE.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\" GRADE == 'G' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems that all the \"G\" correspond to \"A\"\n",
    "df.GRADE.replace('G', 'A', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P assigned to 'Establishment re-opened' actions\n",
    "df.query(\" GRADE == 'P' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P assigned to 'Establishment re-opened' actions\n",
    "df.query(\" GRADE == 'P' \").ACTION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P assigned to 'Reopening Inspection' inspection types\n",
    "df.query(\" GRADE == 'P' \").INSPECTION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.query(\" GRADE == 'Z' \").SCORE.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Figure out what Z, and Not Yet Graded means in GRADE\n",
    "# Until then, we just replace these values with NULL, keeping only the A, B, C grades\n",
    "\n",
    "# \n",
    "df.GRADE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TO_DELETE'] |=  (df.GRADE=='Z')\n",
    "df['TO_DELETE'] |=  (df.GRADE=='P')\n",
    "df['TO_DELETE'] |=  (df.GRADE=='N') # Not Yet Graded\n",
    "df['TO_DELETE'] |=  (df.GRADE=='Not Yet Graded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADE_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"GRADE_DATE\"] = pd.to_datetime(df[\"GRADE_DATE\"], format=\"%m/%d/%Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade date and inspection date should be the same. \n",
    "assert np.abs((df.GRADE_DATE - df.INSPECTION_DATE).dropna()).sum().days == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that is there is a grade date, a grade is also assigned\n",
    "assert sum ( ~df.GRADE_DATE.isnull() & df.GRADE.isnull() )  == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not need GRADE DATE if we have INSPECTION DATE\n",
    "df = df.drop(\"GRADE_DATE\", axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIOLATION_CODE and VIOLATION_DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.VIOLATION_CODE.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the cases where violation code is NULL should be either cases that we delete\n",
    "# or a \"No violations\" case\n",
    "check = df[df.VIOLATION_CODE.isnull() & ~df.TO_DELETE & (df.ACTION!='No violations')]\n",
    "\n",
    "assert( len(check) == 0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.VIOLATION_DESCRIPTION.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks that all VIOLATION_CODE has unique VIOLATION_DESCRIPTION\n",
    "df[['VIOLATION_CODE','VIOLATION_DESCRIPTION']].drop_duplicates().pivot_table(\n",
    "    index='VIOLATION_CODE',\n",
    "    values='VIOLATION_DESCRIPTION',\n",
    "    aggfunc=pd.Series.nunique\n",
    ").sort_values('VIOLATION_DESCRIPTION', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the dataset we have a NULL violation, when there is no violation\n",
    "# To make this more explicit, we replace NULL with 000\n",
    "df.VIOLATION_CODE.fillna('000', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.VIOLATION_CODE.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LATITUDE and LONGITUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LONGITUDE'] = pd.to_numeric(df['LONGITUDE'])\n",
    "df['LATITUDE'] = pd.to_numeric(df['LATITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISC analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the unique values in each column\n",
    "# \n",
    "# df.describe(include = [np.object, 'category']).T['unique']\n",
    "unique = df.describe(include = 'all').T['unique'].sort_values()\n",
    "\n",
    "for column in unique.index:\n",
    "    if unique[column] < 200:\n",
    "        print(df[column].value_counts())\n",
    "        print(\"=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we use the results of the analysis above, and delete (additional) entries that will not be useful in our analysis. (Note that it is important to document this, as others may want to go back to the original source, if the entries that we leave are not sufficient.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df) == initial_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[ df.TO_DELETE == False].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "assert sum(df.INSPECTION_TYPE.isnull()) == 0\n",
    "\n",
    "assert len(set(df.INSPECTION_TYPE.values)) == 2\n",
    "\n",
    "df[\"INSPECTION_TYPE\"] =  pd.Categorical(df[\"INSPECTION_TYPE\"], ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no borough entries are empty\n",
    "assert sum(df.BORO.isnull()) == 0\n",
    "\n",
    "df[\"BORO\"] =  pd.Categorical(df[\"BORO\"], ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no street numbers are empty\n",
    "assert sum(df.BUILDING.isnull()) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(df.STREET.isnull()) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert sum(df.CUISINE_DESCRIPTION.isnull()) == 0\n",
    "\n",
    "df[\"CUISINE_DESCRIPTION\"] =  pd.Categorical(df[\"CUISINE_DESCRIPTION\"], ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only keep three different actions\n",
    "assert len(set(df.ACTION.values)) == 3\n",
    "\n",
    "# No action is empty\n",
    "assert sum(df.ACTION.isnull()) == 0\n",
    "\n",
    "df[\"ACTION\"] =  pd.Categorical(df[\"ACTION\"], ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below drops any grade values other than A, B, C, and converts the remaining entries to null\n",
    "df[\"GRADE\"] =  pd.Categorical(df[\"GRADE\"], categories = ['A', 'B', 'C'], ordered=True)\n",
    "\n",
    "# https://www1.nyc.gov/assets/doh/downloads/pdf/rii/how-we-score-grade.pdf\n",
    "# 0-13 get an A\n",
    "assert sum( (df.GRADE=='A') & (df.SCORE>13)) == 0\n",
    "\n",
    "# 14-27 get a B\n",
    "assert sum( (df.GRADE=='B') & ( (df.SCORE<14) | (df.SCORE>27) ) ) == 0\n",
    "\n",
    "# 28- get a C\n",
    "assert sum( (df.GRADE=='C') & (df.SCORE<28) ) == 0\n",
    "\n",
    "# TODO: In principle, a NULL grade is only when the score is above 14, and it was an initial inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that is there is a grade date, a grade is also assigned\n",
    "# assert sum ( ~df.GRADE_DATE.isnull() & df.GRADE.isnull() ) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"VIOLATION_CODE\"] =  pd.Categorical(df[\"VIOLATION_CODE\"], ordered=False)\n",
    "df[\"CRITICAL_FLAG\"] =  pd.Categorical(df[\"CRITICAL_FLAG\"], ordered=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violation Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreating the table at https://www1.nyc.gov/assets/doh/downloads/pdf/rii/ri-violation-penalty.pdf\n",
    "\n",
    "violation_codes = df [ ['VIOLATION_CODE', 'VIOLATION_DESCRIPTION', 'CRITICAL_FLAG'] ].drop_duplicates()\n",
    "violation_codes = violation_codes.rename( {\n",
    "    'VIOLATION_DESCRIPTION' : 'DESCRIPTION',\n",
    "    'CRITICAL_FLAG' : 'CRITICAL'\n",
    "},  axis = 'columns').sort_values('VIOLATION_CODE').set_index('VIOLATION_CODE')#.drop(np.nan)\n",
    "violation_codes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the description and critical part from the main dataframe\n",
    "df = df.drop(['VIOLATION_DESCRIPTION' ,  'CRITICAL_FLAG'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants =  df [ ['CAMIS', 'DBA', 'BUILDING', 'STREET', 'ZIPCODE', 'BORO', 'PHONE', 'CUISINE_DESCRIPTION'] ].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we have the same attributes for a given CAMIS\n",
    "# and the we do not have duplicate CAMIS values\n",
    "assert len(restaurants) == len(set(restaurants.CAMIS.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Pass the addresses through Google Maps API and get the x and y coordinates and fix zipcodes etc\n",
    "\n",
    "restaurants.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants.PHONE.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __ = restaurants.PHONE.value_counts().head(10).index.values[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restaurants.PHONE.replace(to_replace=__, value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citi Field concessions\n",
    "# restaurants.query(\"PHONE == '7185958100'\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Madison Square Garden concession stands\n",
    "# restaurants.query(\"PHONE == '2124656273'\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants.DBA.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop (['DBA', 'BUILDING', 'STREET', 'ZIPCODE', 'BORO', 'PHONE', 'CUISINE_DESCRIPTION'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each inspection has multiple violations. We want to keep just the inspections for now\n",
    "inspection = df.drop('VIOLATION_CODE', axis='columns').drop_duplicates().sort_values(['INSPECTION_DATE', 'CAMIS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an ID for each inspection here\n",
    "inspection = inspection.reset_index().drop('index', axis='columns').reset_index().rename({'index': 'INSPECTION_ID'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection.ACTION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the inspection table contains \n",
    "# no duplicate pairs for 'INSPECTION_DATE', 'CAMIS'\n",
    "pvt = inspection.pivot_table(\n",
    "    index = ['INSPECTION_DATE', 'CAMIS'],\n",
    "    values = 'INSPECTION_ID',\n",
    "    aggfunc = 'count'\n",
    ")\n",
    "pvt [ pvt.INSPECTION_ID > 1 ]\n",
    "\n",
    "# assert len(pvt [ pvt.INSPECTION_ID > 1 ]) == 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[ (df.CAMIS =='41007054') & (df.INSPECTION_DATE == '2017-03-03')  ].sort_values('VIOLATION_CODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[ (df.CAMIS =='50048062') & (df.INSPECTION_DATE == '2018-10-30')  ].sort_values('VIOLATION_CODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ (df.CAMIS =='40911114') & (df.INSPECTION_DATE == '2017-11-04')  ].sort_values('VIOLATION_CODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[ (df.CAMIS =='41485450') & (df.INSPECTION_DATE == '2018-04-12')  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection.INSPECTION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection_stats = inspection.pivot_table(\n",
    "    index = 'CAMIS',\n",
    "    aggfunc = ['min', 'max', 'count'],\n",
    "    values = 'INSPECTION_DATE'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of last inspection across all restaurants\n",
    "inspection_stats['max'].sort_values('INSPECTION_DATE').reset_index().pivot_table(\n",
    "    index='INSPECTION_DATE',\n",
    "    aggfunc='count'\n",
    ").resample('1W').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longevity \n",
    "# (inspection_stats['max'] - inspection_stats['min'])['INSPECTION DATE'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of all inspections\n",
    "inspection['INSPECTION_DATE'].value_counts().sort_index().resample('1W').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations = pd.merge(\n",
    "    inspection,\n",
    "    df[ ['CAMIS', 'INSPECTION_DATE', 'VIOLATION_CODE' ] ],\n",
    "    on= ['CAMIS', 'INSPECTION_DATE'],\n",
    "    how = 'inner'\n",
    ")\n",
    "violations = violations[ ['INSPECTION_ID', 'VIOLATION_CODE'] ].drop_duplicates()\n",
    "len(violations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Violations: {len(violations)}\")\n",
    "print(f\"Inspections: {len(inspection)}\")\n",
    "print(f\"Restaurants: {len(restaurants)}\")\n",
    "print(f\"Violation Codes: {len(violation_codes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
